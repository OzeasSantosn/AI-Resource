{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - LSTM without any Libraries.......\n",
    "![title](RNN-LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RecurrentNeuralNetwork:\n",
    "    \n",
    "    def __init__ (self, input, output, recurrences, expected_output, learning_rate):\n",
    "        #initial input \n",
    "        self.x = np.zeros(input)\n",
    "        #input size \n",
    "        self.input = input\n",
    "        #expected output \n",
    "        self.y = np.zeros(output)\n",
    "        #output size\n",
    "        self.output = output\n",
    "        #weight matrix \n",
    "        self.w = np.random.random((output, output))\n",
    "        #matrix used in RMSprop in order to decay the learning rate\n",
    "        self.G = np.zeros_like(self.w)\n",
    "        #length of the recurrent network\n",
    "        self.recurrences = recurrences\n",
    "        #learning rate \n",
    "        self.learning_rate = learning_rate\n",
    "        #array for storing inputs\n",
    "        self.ia = np.zeros((recurrences+1,input))\n",
    "        #array for storing cell states\n",
    "        self.ca = np.zeros((recurrences+1,output))\n",
    "        #array for storing outputs\n",
    "        self.oa = np.zeros((recurrences+1,output))\n",
    "        #array for storing hidden states\n",
    "        self.ha = np.zeros((recurrences+1,output))\n",
    "        #forget gate \n",
    "        self.af = np.zeros((recurrences+1,output))\n",
    "        #input gate\n",
    "        self.ai = np.zeros((recurrences+1,output))\n",
    "        #cell state\n",
    "        self.ac = np.zeros((recurrences+1,output))\n",
    "        #output gate\n",
    "        self.ao = np.zeros((recurrences+1,output))\n",
    "        #array of expected output values\n",
    "        self.expected_output = np.vstack((np.zeros(expected_output.shape[0]), expected_output.T))\n",
    "        #declare LSTM cell \n",
    "        self.LSTM = LSTM(input, output, recurrences, learning_rate)\n",
    "    \n",
    "    #sigmoid activation function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    #derivative of sigmoid \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))    \n",
    "    \n",
    "    #Forward Propagation\n",
    "    def forwardProp(self):\n",
    "        for i in range(1, self.recurrences+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, c, o = self.LSTM.forwardProp()\n",
    "            #store cell state from the forward propagation\n",
    "            self.ca[i] = cs #cell state\n",
    "            self.ha[i] = hs #hidden state\n",
    "            self.af[i] = f #forget state\n",
    "            self.ai[i] = inp #inpute gate\n",
    "            self.ac[i] = c #cell state\n",
    "            self.ao[i] = o #output gate\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs)) #activate the weight*input\n",
    "            self.x = self.expected_output[i-1]\n",
    "        return self.oa\n",
    "   \n",
    "    # Back propagation\n",
    "    def backProp(self):\n",
    "        totalError = 0\n",
    "        #cell state\n",
    "        dfcs = np.zeros(self.output)\n",
    "        #hidden state,\n",
    "        dfhs = np.zeros(self.output)\n",
    "        #weight matrix\n",
    "        tu = np.zeros((self.output,self.output))\n",
    "        #forget gate\n",
    "        tfu = np.zeros((self.output, self.input+self.output))\n",
    "        #input gate\n",
    "        tiu = np.zeros((self.output, self.input+self.output))\n",
    "        #cell unit\n",
    "        tcu = np.zeros((self.output, self.input+self.output))\n",
    "        #output gate\n",
    "        tou = np.zeros((self.output, self.input+self.output))\n",
    "        for i in range(self.recurrences, -1, -1):\n",
    "            error = self.oa[i] - self.expected_output[i]\n",
    "            tu += np.dot(np.atleast_2d(error * self.dsigmoid(self.oa[i])), np.atleast_2d(self.ha[i]).T)\n",
    "            error = np.dot(error, self.w)\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.ia[i]))\n",
    "            self.LSTM.cs = self.ca[i]\n",
    "            fu, iu, cu, ou, dfcs, dfhs = self.LSTM.backProp(error, self.ca[i-1], self.af[i], self.ai[i], self.ac[i], self.ao[i], dfcs, dfhs)\n",
    "            totalError += np.sum(error)\n",
    "            #forget gate\n",
    "            tfu += fu\n",
    "            #input gate\n",
    "            tiu += iu\n",
    "            #cell state\n",
    "            tcu += cu\n",
    "            #output gate\n",
    "            tou += ou   \n",
    "        self.LSTM.update(tfu/self.recurrences, tiu/self.recurrences, tcu/self.recurrences, tou/self.recurrences)  \n",
    "        self.update(tu/self.recurrences)\n",
    "        return totalError\n",
    "    \n",
    "    def update(self, u):\n",
    "        self.G = 0.95 * self.G + 0.1 * u**2  \n",
    "        self.w -= self.learning_rate/np.sqrt(self.G + 1e-8) * u\n",
    "        return\n",
    "    \n",
    "    def sample(self):\n",
    "        for i in range(1, self.recurrences+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n",
    "            maxI = np.argmax(self.x)\n",
    "            self.x = np.zeros_like(self.x)\n",
    "            self.x[maxI] = 1\n",
    "            self.ia[i] = self.x \n",
    "            #store cell states\n",
    "            self.ca[i] = cs\n",
    "            #store hidden state\n",
    "            self.ha[i] = hs\n",
    "            #forget gate\n",
    "            self.af[i] = f\n",
    "            #input gate\n",
    "            self.ai[i] = inp\n",
    "            #cell state\n",
    "            self.ac[i] = c\n",
    "            #output gate\n",
    "            self.ao[i] = o\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            maxI = np.argmax(self.oa[i])\n",
    "            newX = np.zeros_like(self.x)\n",
    "            newX[maxI] = 1\n",
    "            self.x = newX\n",
    "           \n",
    "        return self.oa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long short-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    # LSTM cell (input, output, amount of recurrence, learning rate)\n",
    "    def __init__ (self, input, output, recurrences, learning_rate):\n",
    "        #input size\n",
    "        self.x = np.zeros(input+output)\n",
    "        #input size\n",
    "        self.input = input + output\n",
    "        #output \n",
    "        self.y = np.zeros(output)\n",
    "        #output size\n",
    "        self.output = output\n",
    "        #cell state intialized as size of prediction\n",
    "        self.cs = np.zeros(output)\n",
    "        #how often to perform recurrence\n",
    "        self.recurrences = recurrences\n",
    "        #balance the rate of training (learning rate)\n",
    "        self.learning_rate = learning_rate\n",
    "        #init weight matrices for our gates\n",
    "        #forget gate\n",
    "        self.f = np.random.random((output, input+output))\n",
    "        #input gate\n",
    "        self.i = np.random.random((output, input+output))\n",
    "        #cell state\n",
    "        self.c = np.random.random((output, input+output))\n",
    "        #output gate\n",
    "        self.o = np.random.random((output, input+output))\n",
    "        #forget gate gradient\n",
    "        self.Gf = np.zeros_like(self.f)\n",
    "        #input gate gradient\n",
    "        self.Gi = np.zeros_like(self.i)\n",
    "        #cell state gradient\n",
    "        self.Gc = np.zeros_like(self.c)\n",
    "        #output gate gradient\n",
    "        self.Go = np.zeros_like(self.o)\n",
    "    \n",
    "   \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    \n",
    "    def tangent(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    \n",
    "    def dtangent(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "  \n",
    "    def forwardProp(self):\n",
    "        f = self.sigmoid(np.dot(self.f, self.x))\n",
    "        self.cs *= f\n",
    "        i = self.sigmoid(np.dot(self.i, self.x))\n",
    "        c = self.tangent(np.dot(self.c, self.x))\n",
    "        self.cs += i * c\n",
    "        o = self.sigmoid(np.dot(self.o, self.x))\n",
    "        self.y = o * self.tangent(self.cs)\n",
    "        return self.cs, self.y, f, i, c, o\n",
    "    \n",
    "   \n",
    "    def backProp(self, e, pcs, f, i, c, o, dfcs, dfhs):\n",
    "        \n",
    "        e = np.clip(e + dfhs, -6, 6)\n",
    "        \n",
    "        do = self.tangent(self.cs) * e\n",
    "        \n",
    "        ou = np.dot(np.atleast_2d(do * self.dtangent(o)).T, np.atleast_2d(self.x))\n",
    "        \n",
    "        dcs = np.clip(e * o * self.dtangent(self.cs) + dfcs, -6, 6)\n",
    "        \n",
    "        dc = dcs * i\n",
    "    \n",
    "        cu = np.dot(np.atleast_2d(dc * self.dtangent(c)).T, np.atleast_2d(self.x))\n",
    "      \n",
    "        di = dcs * c\n",
    "        \n",
    "        iu = np.dot(np.atleast_2d(di * self.dsigmoid(i)).T, np.atleast_2d(self.x))\n",
    "       \n",
    "        df = dcs * pcs\n",
    "        \n",
    "        fu = np.dot(np.atleast_2d(df * self.dsigmoid(f)).T, np.atleast_2d(self.x))\n",
    "       \n",
    "        dpcs = dcs * f\n",
    "        \n",
    "        dphs = np.dot(dc, self.c)[:self.output] + np.dot(do, self.o)[:self.output] + np.dot(di, self.i)[:self.output] + np.dot(df, self.f)[:self.output] \n",
    "       \n",
    "        return fu, iu, cu, ou, dpcs, dphs\n",
    "            \n",
    "    def update(self, fu, iu, cu, ou):\n",
    "        #Update forget, input, cell, and output gradients\n",
    "        self.Gf = 0.9 * self.Gf + 0.1 * fu**2 \n",
    "        self.Gi = 0.9 * self.Gi + 0.1 * iu**2   \n",
    "        self.Gc = 0.9 * self.Gc + 0.1 * cu**2   \n",
    "        self.Go = 0.9 * self.Go + 0.1 * ou**2   \n",
    "        \n",
    "        #Update our gates using our gradients\n",
    "        self.f -= self.learning_rate/np.sqrt(self.Gf + 1e-8) * fu\n",
    "        self.i -= self.learning_rate/np.sqrt(self.Gi + 1e-8) * iu\n",
    "        self.c -= self.learning_rate/np.sqrt(self.Gc + 1e-8) * cu\n",
    "        self.o -= self.learning_rate/np.sqrt(self.Go + 1e-8) * ou\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 5574\n",
      "Number of scenes: 1556\n",
      "Average number of sentences in each scene: 1.3823907455012854\n",
      "Number of lines: 3707\n",
      "Average number of words in each line: 5.990828162934988\n",
      "\n",
      "The sentences 0 to 50:\n",
      " guard unlocks a cell block to call the inmates out for their\n",
      "lunch.\n",
      "\n",
      "        Guard:\n",
      "Lunch time.\n",
      "\n",
      "Inmates exit their cells and are murmuring amongst themselves.\n",
      "\n",
      "        Guard:\n",
      "The longer you animals bark the colder your lunch gets. Come on, move\n",
      "it out! (Looks toward the last occupied cell) You too down there.\n",
      "(Walks down the cellblock) Hey turkey...\n",
      "\n",
      "Guard walks down to an open cell where the expected inmate has not\n",
      "emerged. He walks in and discovers that the inmate, Jake Fratelli, has\n",
      "apparently hung himself. There is a note taped to his chest reading,\n",
      "\"To whom it may concern\". The guard removes it, turns it over and\n",
      "reads the back.\n",
      "\n",
      "        Guard:\n",
      "\"You schmuck. Do you really think I'd be stupid enough to kill\n",
      "myself?\" (Repeats last two words to himself in bewilderment) Kill\n",
      "myself?\n",
      "\n",
      "Jake was alive. He opens his eyes, cocks his head and grins,\n",
      "assaulting the unsuspecting guard, knocking him out. Jake untangles\n",
      "himself from his makeshift gallows, removing a pipe assembly from his\n",
      "beltline which supported his weight.\n",
      "\n",
      "Scene 2: Exterior Jailhouse\n",
      "\n",
      "Francis Fratelli, Jake's brother, is pouring a ring of gasoline around\n",
      "the front entrance, while their mother, Mama Fratelli, waits anxiously\n",
      "behind the wheel of their ORV.\n",
      "\n",
      "        Mama F:\n",
      "Come on!\n",
      "\n",
      "Francis throws the empty gasoline can in the back of the ORV and then\n",
      "jumps into the passenger seat, loading a semi-automatic pistol. Jake\n",
      "hurries down the front steps of the jailhouse in his street clothes.\n",
      "\n",
      "        Mama F:\n",
      "Here he comes.\n",
      "\n",
      "Mama starts the car as Jake runs over to the right rear door. It's\n",
      "locked.\n",
      "\n",
      "        Jake:\n",
      "Francis, it's the lock. (Desperate to open the car door) The lock,\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "data_dir = 'input.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "view_sentence_range = (0, 50)\n",
    "text = text[81:]\n",
    "\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "    vocab = set(text)\n",
    "    vocab_to_int = {w: i for i, w in enumerate(vocab)}\n",
    "    int_to_vocab = dict(enumerate(vocab))\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "def token_lookup():\n",
    "    return {'.':'||period||', \n",
    "            ',':'||comma||', \n",
    "            '\"':'||double_quotes||',\n",
    "            ';':'||semicolon||',\n",
    "            '!':'||exclamation_mark||',\n",
    "            '?':'||question_mark||',\n",
    "            '(':'||left_paren||',\n",
    "            ')':'||right_paren||',\n",
    "            '--':'||dash||',\n",
    "            '\\n':'||newline||'}\n",
    "\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inititialization And Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Initialize Hyperparameters\")\n",
    "iterations = 10000\n",
    "learningRate = 0.001\n",
    "print(\"Reading Input/Output data from disk\")\n",
    "returnData, numCategories, expectedOutput, outputSize, data = read_text_file()\n",
    "\n",
    "print(\"Reading from disk done. Proceeding with training.\")\n",
    "#Initialize the RNN using our hyperparameters and data\n",
    "RNN = RecurrentNeuralNetwork(numCategories, numCategories, outputSize, expectedOutput, learningRate)\n",
    "\n",
    "#training time!\n",
    "for i in range(1, iterations):\n",
    "    #Predict the next word of each word\n",
    "    RNN.forwardProp()\n",
    "    #update all our weights using our error\n",
    "    error = RNN.backProp()\n",
    "    #For a given error threshold\n",
    "    print(\"Reporting error on iteration \", i, \": \", error)\n",
    "    if error > -10 and error < 10 or i % 10 == 0:\n",
    "        #We provide a seed word\n",
    "        seed = np.zeros_like(RNN.x)\n",
    "        maxI = np.argmax(np.random.random(RNN.x.shape))\n",
    "        seed[maxI] = 1\n",
    "        RNN.x = seed  \n",
    "        #and predict the upcoming one\n",
    "        output = RNN.sample()\n",
    "        print(output)    \n",
    "        #finally, we store it to disk\n",
    "        export_to_textfile(output, data)\n",
    "        print(\"Done Writing\")\n",
    "print(\"Train/Prediction routine complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
